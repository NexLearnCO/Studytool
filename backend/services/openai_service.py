import openai
from config import Config

class OpenAIService:
    def __init__(self):
        openai.api_key = Config.OPENAI_API_KEY
        self.model = Config.OPENAI_MODEL
        
    def generate_notes(self, content, detail_level='medium', language='zh-tw', content_type='general'):
        """Generate notes from content using OpenAI with enhanced prompts and smart content handling"""
        
        # Handle very large content by intelligent chunking if needed
        if len(content) > 15000:  # ~15k characters is roughly safe limit for context
            return self._generate_notes_chunked(content, detail_level, language, content_type)
        
        # Get optimized prompt based on detail level, language, and content type
        prompt = self._create_prompt(content, detail_level, language, content_type)
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "You are an expert note-taker who creates well-structured study notes in Markdown format. Provide content directly without meta-commentary or conclusive summaries."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=Config.OPENAI_MAX_TOKENS,
                temperature=Config.OPENAI_TEMPERATURE
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Failed to generate notes: {str(e)}")
    
    def _generate_notes_chunked(self, content, detail_level, language, content_type):
        """Handle very large content by chunking and combining results"""
        
        # Split content into manageable chunks
        chunk_size = 12000  # Safe chunk size
        chunks = []
        
        for i in range(0, len(content), chunk_size):
            chunk = content[i:i + chunk_size]
            chunks.append(chunk)
        
        # Generate notes for each chunk
        chunk_notes = []
        for i, chunk in enumerate(chunks):
            try:
                prompt = self._create_prompt(chunk, detail_level, language, content_type)
                
                # Add chunk context
                if len(chunks) > 1:
                    prompt += f"\n\næ³¨æ„ï¼šé€™æ˜¯ç¬¬ {i+1} éƒ¨åˆ†ï¼Œå…± {len(chunks)} éƒ¨åˆ†ã€‚è«‹ç¢ºä¿å…§å®¹éŠœæ¥è‡ªç„¶ã€‚ä¸è¦æ·»åŠ ç¸½çµæ€§çµå°¾ï¼Œç›´æ¥ä»¥å…§å®¹çµæŸã€‚"
                
                response = openai.ChatCompletion.create(
                    model=Config.OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": "You are an expert note-taker who creates well-structured study notes in Markdown format. Provide content directly without meta-commentary or conclusive summaries."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=Config.OPENAI_MAX_TOKENS,
                    temperature=Config.OPENAI_TEMPERATURE
                )
                
                chunk_notes.append(response.choices[0].message.content)
                
            except Exception as e:
                chunk_notes.append(f"## ç¬¬ {i+1} éƒ¨åˆ†è™•ç†éŒ¯èª¤\n\néŒ¯èª¤: {str(e)}")
        
        # Combine all chunk notes
        if len(chunk_notes) == 1:
            return chunk_notes[0]
        
        # Create a unified document from chunks
        combined_notes = "# å®Œæ•´å­¸ç¿’ç­†è¨˜\n\n"
        for i, notes in enumerate(chunk_notes):
            # Remove duplicate headers and combine
            clean_notes = notes.replace("# ", "## ").replace("##", f"## ç¬¬ {i+1} éƒ¨åˆ† - ")
            combined_notes += clean_notes + "\n\n---\n\n"
        
        return combined_notes.rstrip("\n---\n")
    
    def _create_prompt(self, content, detail_level, language='zh-tw', content_type='general'):
        """Create optimized prompt for note generation based on Claude Opus 4.1 suggestions"""
        
        # Enhanced detail level instructions
        detail_instructions = {
            'brief': """å°ˆæ³¨æ–¼æœ€æ ¸å¿ƒçš„æ¦‚å¿µå’Œè¦é»ã€‚å‰µå»ºç°¡æ½”ä½†å®Œæ•´çš„ç­†è¨˜ï¼š
- åªåŒ…å«å¿…é ˆæŒæ¡çš„é—œéµæ¦‚å¿µ
- æ¯å€‹ä¸»é¡Œé™åˆ¶åœ¨æœ€é‡è¦çš„2-3å€‹è¦é»
- ä½¿ç”¨ç°¡æ½”çš„èªè¨€ï¼Œé¿å…å†—é¤˜
- é©åˆå¿«é€Ÿå¾©ç¿’å’Œæ¦‚è¦½
- ä¿æŒé‚è¼¯æ¸…æ™°ä½†å…§å®¹ç²¾ç°¡""",
            
            'medium': """å‰µå»ºå¹³è¡¡ä½†å…¨é¢çš„è©³ç´°ç­†è¨˜ï¼š
ã€æ ¸å¿ƒè¦æ±‚ã€‘
- åŒ…å«æ‰€æœ‰ä¸»è¦æ¦‚å¿µçš„å®Œæ•´è§£é‡‹
- æä¾›é—œéµä¾‹å­çš„è©³ç´°åˆ†æ
- åŒ…å«é‡è¦çš„å…¬å¼ã€æ•¸æ“šå’Œæ­¥é©Ÿ
- è§£é‡‹æ¦‚å¿µé–“çš„é—œä¿‚å’Œé€£çµ

ã€è©³ç´°ç¨‹åº¦ã€‘
- æ¯å€‹æ¦‚å¿µéƒ½è¦æœ‰å……åˆ†çš„è§£é‡‹
- åŒ…å«è‡³å°‘2-3å€‹å…¸å‹ä¾‹å­
- æä¾›å¯¦ç”¨çš„è­˜åˆ¥æ–¹æ³•å’ŒæŠ€å·§
- é©åˆæ·±åº¦å­¸ç¿’ï¼Œä¸åªæ˜¯æ¦‚è¦½""",
            
            'detailed': """å‰µå»ºæ¥µå…¶è©³ç›¡ã€å…¨é¢çš„å­¸ç¿’ç­†è¨˜ï¼š
ã€å®Œæ•´æ€§è¦æ±‚ã€‘
- åŒ…å«æºå…§å®¹ä¸­çš„ALLä¿¡æ¯ï¼Œä¸éºæ¼ä»»ä½•ç´°ç¯€
- æä¾›COMPLETEè§£é‡‹ï¼Œä¸åªæ˜¯ç¸½çµ
- åŒ…å«æ‰€æœ‰æåŠçš„ä¾‹å­ã€æ•¸æ“šã€å…¬å¼ã€æ­¥é©Ÿ
- è§£é‡‹"ç‚ºä»€éº¼"ï¼Œä¸åªæ˜¯"æ˜¯ä»€éº¼"

ã€è©³ç´°ç¨‹åº¦æ¨™æº–ã€‘
- æ²’çœ‹éåŸå…§å®¹çš„äººæ‡‰è©²å®Œå…¨ç†è§£ä¸»é¡Œ
- è¶³å¤ è©³ç´°ç”¨æ–¼è€ƒè©¦æº–å‚™
- é©åˆåˆå­¸å’Œå¾©ç¿’é›™é‡ç”¨é€”
- çµ•ä¸ä½¿ç”¨ç¸®ç•¥è§£é‡‹ - å¿…é ˆå¾¹åº•å®Œæ•´"""
        }
        
        # Enhanced language-specific instructions
        language_instructions = {
            'en': "Create comprehensive study notes in English. Use clear, academic English suitable for learning and review. Ensure professional terminology and proper grammar throughout.",
            'zh-cn': "è¯·ç”¨ç®€ä½“ä¸­æ–‡åˆ›å»ºå…¨é¢çš„å­¦ä¹ ç¬”è®°ã€‚ä½¿ç”¨æ¸…æ™°ã€å­¦æœ¯åŒ–çš„ä¸­æ–‡è¡¨è¾¾ï¼Œé€‚åˆå­¦ä¹ å’Œå¤ä¹ ã€‚ç¡®ä¿ä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼Œè¯­æ³•è§„èŒƒã€‚",
            'zh-tw': "è«‹ç”¨ç¹é«”ä¸­æ–‡å‰µå»ºå…¨é¢çš„å­¸ç¿’ç­†è¨˜ã€‚ä½¿ç”¨æ¸…æ™°ã€å­¸è¡“åŒ–çš„ä¸­æ–‡è¡¨é”ï¼Œé©åˆå­¸ç¿’å’Œè¤‡ç¿’ã€‚ç¢ºä¿å°ˆæ¥­è¡“èªæº–ç¢ºï¼Œèªæ³•è¦ç¯„ã€‚"
        }
        
        # Content-type specific instructions
        content_type_instructions = {
            'youtube': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸ç¿’ç­†è¨˜å°ˆå®¶ã€‚è«‹å¾æä¾›çš„ YouTube å½±ç‰‡è½‰éŒ„æ–‡æœ¬å‰µå»ºé«˜è³ªé‡çš„å­¸ç¿’ç­†è¨˜ã€‚

## åˆ†ææ–¹æ³•ï¼š
1. **å®Œæ•´ç†è§£å…§å®¹** - ä»”ç´°é–±è®€æ•´å€‹è½‰éŒ„æ–‡æœ¬ï¼Œè­˜åˆ¥ä¸»è¦æ¦‚å¿µå’Œé—œéµä¿¡æ¯ï¼Œéæ¿¾æ‰å¡«å……è©ã€é‡è¤‡å…§å®¹å’Œéæ•™è‚²æ€§å…§å®¹
2. **çµæ§‹åŒ–çµ„ç¹”** - æŒ‰ä¸»é¡Œè€Œéæ™‚é–“é †åºçµ„ç¹”ï¼Œå¾åŸºç¤æ¦‚å¿µåˆ°é€²éšå…§å®¹ï¼Œå‰µå»ºæ¸…æ™°çš„å±¤æ¬¡çµæ§‹
3. **å…§å®¹è¦æ±‚** - åŒ…å«æ‰€æœ‰é‡è¦ä¿¡æ¯é»ï¼Œä¿ç•™å…·é«”ä¾‹å­å’Œæ•¸æ“šï¼Œçªå‡ºé—œéµè¡“èªå’Œå®šç¾©""",
            
            'pdf': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸è¡“ç­†è¨˜æ•´ç†å°ˆå®¶ã€‚è«‹å°‡æä¾›çš„ PDF æ–‡æœ¬å…§å®¹è½‰æ›ç‚ºçµæ§‹åŒ–çš„å­¸ç¿’ç­†è¨˜ã€‚

## è™•ç†ç­–ç•¥ï¼š
1. **æ–‡æœ¬åˆ†æ** - è­˜åˆ¥ç« ç¯€çµæ§‹å’Œä¸»è¦è«–é»ï¼Œæå–é—œéµæ¦‚å¿µã€å®šç¾©å’Œç†è«–ï¼Œä¿ç•™é‡è¦çš„æ•¸æ“šã€çµ±è¨ˆå’Œå¼•ç”¨
2. **çŸ¥è­˜æ•´åˆ** - æŒ‰æ¦‚å¿µä¸»é¡Œé‡æ–°çµ„ç¹”å…§å®¹ï¼Œå»ºç«‹æ¦‚å¿µä¹‹é–“çš„é‚è¼¯è¯ç¹«ï¼Œçªå‡ºé‡è¦çš„å­¸è¡“è¦é»
3. **å­¸ç¿’å„ªåŒ–** - ç°¡åŒ–è¤‡é›œå¥å­ä½†ä¿ç•™åŸæ„ï¼Œæ·»åŠ é‚è¼¯é€£æ¥è©å¢å¼·å¯è®€æ€§ï¼Œå¼·èª¿å¯è€ƒè©¦çš„é‡é»å…§å®¹""",
            
            'general': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹çµ„ç¹”å°ˆå®¶ã€‚è«‹å°‡æä¾›çš„æ–‡æœ¬å…§å®¹è½‰æ›ç‚ºçµæ§‹åŒ–çš„å­¸ç¿’ç­†è¨˜ã€‚

## è™•ç†æµç¨‹ï¼š
1. **å…§å®¹ç†è§£** - å…¨é¢åˆ†ææ–‡æœ¬çµæ§‹å’Œæ ¸å¿ƒä¸»é¡Œï¼Œè­˜åˆ¥ä¸»è¦è«–é»å’Œæ”¯æŒä¿¡æ¯
2. **çµæ§‹é‡çµ„** - æŒ‰é‚è¼¯ä¸»é¡Œé‡æ–°æ’åˆ—å…§å®¹ï¼Œå‰µå»ºæ¸…æ™°çš„ä¿¡æ¯å±¤æ¬¡ï¼Œå»ºç«‹æ¦‚å¿µé–“çš„é—œè¯
3. **å­¸ç¿’å°å‘** - å„ªåŒ–å…§å®¹ä»¥ä¾¿ç†è§£å’Œè¨˜æ†¶ï¼Œå¼·èª¿å¯æ“ä½œçš„çŸ¥è­˜é»ï¼Œé©åˆä¸åŒå­¸ç¿’é¢¨æ ¼"""
        }
        
        detail_instruction = detail_instructions.get(detail_level, detail_instructions['medium'])
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        content_instruction = content_type_instructions.get(content_type, content_type_instructions['general'])
        
        prompt = f"""
{content_instruction}

## è©³ç´°ç¨‹åº¦è¦æ±‚ï¼š
{detail_instruction}

## æ ¼å¼è¦æ±‚ï¼š

### 1. çµæ§‹èˆ‡æ ¼å¼åŒ–
- ä½¿ç”¨æ¸…æ™°çš„è¡¨æƒ…ç¬¦è™Ÿåœ–æ¨™æ¨™ç¤ºä¸»è¦ç« ç¯€ (ğŸ”„, ğŸ§ª, ğŸ“Š, âš—ï¸, ğŸ“ˆ, ğŸ’¡ç­‰)
- å‰µå»ºå¤šå±¤æ¬¡æ¨™é¡Œçµæ§‹ (H1, H2, H3, H4)
- ç‚ºæ¯”è¼ƒå’Œé—œä¿‚å‰µå»ºè¡¨æ ¼
- ä½¿ç”¨é …ç›®ç¬¦è™Ÿåˆ—è¡¨
- **ç²—é«”**æ¨™ç¤ºé—œéµè¡“èªå’Œå®šç¾©
- åŒ…å«ç›¸é—œçš„å…¬å¼/æ–¹ç¨‹å¼

### 2. å…§å®¹æ·±åº¦è¦æ±‚
- æä¾›**å®Œæ•´**è§£é‡‹ï¼Œè€Œéåƒ…åƒ…ç¸½çµ
- åŒ…å«æºå…§å®¹ä¸­æåŠçš„**æ‰€æœ‰**ä¾‹å­
- é¡¯ç¤ºé€æ­¥éç¨‹
- åŒ…å«å…·é«”æ•¸å­—ã€å…¬å¼å’Œæ•¸æ“š
- è§£é‡‹æ¦‚å¿µèƒŒå¾Œçš„"ç‚ºä»€éº¼"ï¼Œä¸åªæ˜¯"æ˜¯ä»€éº¼"

### 3. è¦–è¦ºçµ„ç¹”
- ç‚ºç›¸é—œæ¦‚å¿µå‰µå»ºæ¯”è¼ƒè¡¨æ ¼
- ç‚ºé‡è¦å®šç¾©ä½¿ç”¨æ ¼å¼åŒ–æ¡†
- åŒ…å«éç¨‹æµç¨‹åœ– (æ­¥é©Ÿ1 â†’ æ­¥é©Ÿ2 â†’ æ­¥é©Ÿ3)
- åœ¨æ¸…æ™°ç« ç¯€ä¸­åˆ†é›¢ä¾‹å­
- å°é¡ä¼¼å…§å®¹é¡å‹ä½¿ç”¨ä¸€è‡´æ ¼å¼

### 4. å…·é«”åŒ…å«å…§å®¹

**å°æ–¼æ¦‚å¿µï¼š**
- å®Œæ•´å®šç¾©
- é‹ä½œæ–¹å¼
- é‡è¦æ€§åŸå› 
- ç›¸é—œæ¦‚å¿µ

**å°æ–¼éç¨‹ï¼š**
- æ¯å€‹æ­¥é©Ÿçš„è©³ç´°è§£é‡‹
- æ¯å€‹éšæ®µç™¼ç”Ÿä»€éº¼
- å¸¸è¦‹è®ŠåŒ–

**å°æ–¼ä¾‹å­ï¼š**
- å®Œæ•´çš„æ–¹ç¨‹å¼/å…¬å¼
- é€æ­¥åˆ†æ
- è­˜åˆ¥æ‰€æœ‰çµ„æˆéƒ¨åˆ†
- è§£é‡‹çµæœ

**å°æ–¼è¦å‰‡/åŸç†ï¼š**
- æ¸…æ¥šé™³è¿°è¦å‰‡
- åˆ—å‡ºæ‰€æœ‰ä¾‹å¤–
- æä¾›æ‡‰ç”¨ä¾‹å­
- å¸¸è¦‹èª¤è§£

### 5. è¡¨æ ¼æ ¼å¼è¦æ±‚
```
| æ¬„ä½1 | æ¬„ä½2 | æ¬„ä½3 |
|-------|-------|-------|
| æ¦‚å¿µ | å®šç¾© | ä¾‹å­ |
| éç¨‹ | ç™¼ç”Ÿä»€éº¼ | çµæœ |
| æ¯”è¼ƒ | é …ç›®A | é …ç›®B |
```

### 6. ä¾‹å­æ ¼å¼
```
### ä¾‹å­X: [æ¨™é¡Œ]
**çµ¦å®šï¼š** [åˆå§‹æ¢ä»¶]
**éç¨‹ï¼š**
- æ­¥é©Ÿ1: [è©³ç´°è§£é‡‹]
- æ­¥é©Ÿ2: [ä»€éº¼æ”¹è®ŠåŠç‚ºä»€éº¼]

**è­˜åˆ¥ï¼š**
- çµ„æˆ1: [è§’è‰²å’Œè®ŠåŒ–]
- çµ„æˆ2: [è§’è‰²å’Œè®ŠåŒ–]

**çµæœï¼š** [æœ€çµ‚çµæœåŠè§£é‡‹]
```

### 7. å¿…é ˆåŒ…å«çš„é—œéµç« ç¯€
- ğŸ¯ æ¦‚è¦½/ä»‹ç´¹
- ğŸ§  æ ¸å¿ƒæ¦‚å¿µï¼ˆå®Œæ•´è§£é‡‹ï¼‰
- âš™ï¸ è©³ç´°æ©Ÿåˆ¶/éç¨‹
- ğŸ“ å¤šå€‹å®Œæ•´ä¾‹å­
- âš ï¸ ç‰¹æ®Šæƒ…æ³å’Œä¾‹å¤–
- ğŸ“‹ å¿«é€Ÿåƒè€ƒ/ç¸½çµ
- ğŸ” è­˜åˆ¥æ–¹æ³•/æŠ€å·§

## è³ªé‡æ¨™æº–ï¼š
- âœ… æ²’çœ‹éåŸå…§å®¹çš„äººæ‡‰è©²å®Œå…¨ç†è§£ä¸»é¡Œ
- âœ… è¶³å¤ è©³ç´°ç”¨æ–¼è€ƒè©¦æº–å‚™  
- âœ… é©åˆåˆå­¸å’Œå¾©ç¿’é›™é‡ç”¨é€”
- âœ… åŒ…å«å¯¦éš›åŒ–å­¸å…¬å¼ï¼Œä¸åªæ˜¯åç¨±
- âœ… é¡¯ç¤ºæ°§åŒ–æ…‹æ¨™è¨˜ (+2, -1ç­‰)
- âœ… åŒ…å«é›»å­è½‰ç§»æ–¹ç¨‹å¼
- âœ… è§£é‡‹æ¦‚å¿µé–“é—œä¿‚
- âœ… æä¾›è¨˜æ†¶è¼”åŠ©å’Œæ¨¡å¼è­˜åˆ¥
- âœ… çµ•ä¸ä½¿ç”¨ç¸®ç•¥è§£é‡‹ - å¿…é ˆå¾¹åº•å®Œæ•´

**æ ¼å¼è¦æ±‚ï¼š**
- ç›´æ¥æä¾›å­¸ç¿’å…§å®¹ï¼Œä¸è¦æ·»åŠ ç¸½çµæ€§çµå°¾
- ä¸è¦åŒ…å«"é€™äº›ç­†è¨˜æä¾›äº†..."æˆ–"ç†è§£é€™äº›æ¦‚å¿µå¾ˆé‡è¦"ç­‰ç¸½çµèªå¥
- ç­†è¨˜æ‡‰è©²ä»¥å¯¦éš›å…§å®¹çµæŸï¼Œè€Œä¸æ˜¯å…ƒè©•è«–
- ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿå’Œè¡¨æ ¼å¢å¼·è¦–è¦ºæ•ˆæœ
- ç‚ºæ‰€æœ‰ä¾‹å­æä¾›å®Œæ•´çš„é€æ­¥åˆ†æ

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

è«‹å‰µå»ºä¸€ä»½å°ˆæ¥­çš„å­¸ç¿’ç­†è¨˜ï¼Œç›´æ¥æä¾›å­¸ç¿’å…§å®¹ï¼Œç„¡éœ€ç¸½çµæ€§çµå°¾ã€‚

---

**å…§å®¹ä¾†æºï¼š**
{content}
"""
        return prompt
    
    def generate_flashcards(self, notes, count=15, difficulty='medium', types=['definition', 'example'], language='zh-tw'):
        """Generate enhanced flashcards from notes using optimized prompts"""
        
        # Enhanced language-specific instructions for flashcards
        language_instructions = {
            'en': "Create flashcards in English with clear, academic terminology. Design questions that test understanding and memory effectively.",
            'zh-cn': "åˆ›å»ºç®€ä½“ä¸­æ–‡å­¦ä¹ å¡ç‰‡ã€‚è®¾è®¡èƒ½æœ‰æ•ˆæµ‹è¯•ç†è§£å’Œè®°å¿†çš„é—®é¢˜ï¼Œä½¿ç”¨å‡†ç¡®çš„å­¦æœ¯æœ¯è¯­ã€‚",
            'zh-tw': "å‰µå»ºç¹é«”ä¸­æ–‡å­¸ç¿’å¡ç‰‡ã€‚è¨­è¨ˆèƒ½æœ‰æ•ˆæ¸¬è©¦ç†è§£å’Œè¨˜æ†¶çš„å•é¡Œï¼Œä½¿ç”¨æº–ç¢ºçš„å­¸è¡“è¡“èªã€‚"
        }
        
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        # Define card types in different languages
        type_descriptions = {
            'en': {
                'definition': 'Definition/explanation cards',
                'example': 'Example/illustration cards', 
                'application': 'Application/problem-solving cards',
                'comparison': 'Comparison/contrast cards'
            },
            'zh-cn': {
                'definition': 'å®šä¹‰è§£é‡Šç±»å¡ç‰‡',
                'example': 'ä¸¾ä¾‹è¯´æ˜ç±»å¡ç‰‡',
                'application': 'åº”ç”¨ç»ƒä¹ ç±»å¡ç‰‡', 
                'comparison': 'æ¯”è¾ƒåˆ†æç±»å¡ç‰‡'
            },
            'zh-tw': {
                'definition': 'å®šç¾©è§£é‡‹é¡å¡ç‰‡',
                'example': 'èˆ‰ä¾‹èªªæ˜é¡å¡ç‰‡',
                'application': 'æ‡‰ç”¨ç·´ç¿’é¡å¡ç‰‡',
                'comparison': 'æ¯”è¼ƒåˆ†æé¡å¡ç‰‡'
            }
        }
        
        type_desc = type_descriptions.get(language, type_descriptions['zh-tw'])
        selected_types = [type_desc[t] for t in types if t in type_desc]

        prompt = f"""
åŸºæ–¼æä¾›çš„å­¸ç¿’ç­†è¨˜ï¼Œå‰µå»º {count} å¼µé«˜è³ªé‡çš„è¨˜æ†¶å¡ç‰‡ç”¨æ–¼å­¸ç¿’å¾©ç¿’ã€‚

## å¡ç‰‡è¦æ±‚ï¼š
- æ•¸é‡ï¼š{count} å¼µ
- é›£åº¦ï¼š{difficulty}
- åŒ…å«é¡å‹ï¼š{', '.join(selected_types)}

## å¡ç‰‡è¨­è¨ˆåŸå‰‡ï¼š

1. **å•é¡Œè¨­è¨ˆ**
   - é‡å°é—œéµæ¦‚å¿µå‰µå»ºæ˜ç¢ºçš„å•é¡Œ
   - ä½¿ç”¨ä¸åŒé¡å‹çš„å•é¡Œï¼ˆå®šç¾©ã€æ‡‰ç”¨ã€æ¯”è¼ƒç­‰ï¼‰
   - ç¢ºä¿å•é¡Œå…·æœ‰æŒ‘æˆ°æ€§ä½†å¯å›ç­”
   - é¿å…éæ–¼æ¨¡ç³Šæˆ–éæ–¼ç°¡å–®çš„å•é¡Œ

2. **ç­”æ¡ˆè¦æ±‚**
   - æä¾›æº–ç¢ºã€å®Œæ•´çš„ç­”æ¡ˆ
   - åŒ…å«è¶³å¤ çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
   - ä½¿ç”¨æ¸…æ™°çš„è§£é‡‹å’Œä¾‹å­
   - é©åˆè¨˜æ†¶å’Œç†è§£

3. **å­¸ç¿’æ•ˆæœ**
   - æ¶µè“‹ç­†è¨˜ä¸­çš„æ‰€æœ‰é‡è¦æ¦‚å¿µ
   - å¹³è¡¡è¨˜æ†¶å’Œç†è§£é¡å•é¡Œ
   - æ”¯æŒé–“éš”é‡è¤‡å­¸ç¿’æ³•
   - é©åˆè‡ªæˆ‘æ¸¬è©¦

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

**æ ¼å¼è¦æ±‚ï¼š**
è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å« 10 å¼µå¡ç‰‡ï¼š

[
  {{"question": "æ¸…æ™°çš„å•é¡Œ", "answer": "è©³ç´°çš„ç­”æ¡ˆ"}},
  {{"question": "å¦ä¸€å€‹å•é¡Œ", "answer": "å°æ‡‰çš„ç­”æ¡ˆ"}}
]

åŸºæ–¼ä»¥ä¸‹ç­†è¨˜å…§å®¹å‰µå»ºè¨˜æ†¶å¡ç‰‡ï¼š
{notes}
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,  # Increased for better flashcards
                temperature=0.5
            )
            
            content = response.choices[0].message.content
            
            # Parse JSON response
            import json
            import re
            
            try:
                # Try direct JSON parse
                flashcards = json.loads(content)
            except json.JSONDecodeError:
                # Extract JSON from response if it's wrapped in text
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    flashcards = json.loads(json_match.group())
                else:
                    # Fallback: create simple flashcards
                    flashcards = [
                        {
                            "question": "What is the main topic of these notes?",
                            "answer": "Based on the provided content, this covers the key concepts discussed in the notes."
                        }
                    ]
            
            return flashcards
            
        except Exception as e:
            raise Exception(f"Failed to generate flashcards: {str(e)}")
    
    def generate_quiz(self, notes, language='zh-tw'):
        """Generate quiz from notes"""
        
        # Language-specific instructions for quiz
        language_instructions = {
            'en': "Create quiz questions in English. Make questions educational and clear.",
            'zh-cn': "åˆ›å»ºç®€ä½“ä¸­æ–‡æµ‹éªŒé¢˜ç›®ã€‚é¢˜ç›®è¦æœ‰æ•™è‚²æ„ä¹‰ä¸”æ¸…æ™°ã€‚",
            'zh-tw': "å‰µå»ºç¹é«”ä¸­æ–‡æ¸¬é©—é¡Œç›®ã€‚é¡Œç›®è¦æœ‰æ•™è‚²æ„ç¾©ä¸”æ¸…æ™°ã€‚"
        }
        
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        prompt = f"""
åŸºæ–¼æä¾›çš„å­¸ç¿’ç­†è¨˜ï¼Œå‰µå»ºä¸€å€‹å…¨é¢çš„é¸æ“‡é¡Œæ¸¬é©—ä¾†è©•ä¼°å­¸ç¿’æ•ˆæœã€‚

## æ¸¬é©—è¨­è¨ˆæ¨™æº–ï¼š

1. **é¡Œç›®è³ªé‡**
   - æ¶µè“‹ç­†è¨˜ä¸­çš„é—œéµçŸ¥è­˜é»
   - æ¸¬è©¦ä¸åŒå±¤æ¬¡çš„ç†è§£ï¼ˆè¨˜æ†¶ã€ç†è§£ã€æ‡‰ç”¨ï¼‰
   - å•é¡Œè¡¨è¿°æ¸…æ™°ç„¡æ­§ç¾©
   - é©ç•¶çš„é›£åº¦åˆ†ä½ˆ

2. **é¸é …è¨­è¨ˆ**
   - ä¸€å€‹æ­£ç¢ºç­”æ¡ˆï¼Œä¸‰å€‹åˆç†çš„å¹²æ“¾é …
   - å¹²æ“¾é …è¦æœ‰è¿·æƒ‘æ€§ä½†æ˜ç¢ºéŒ¯èª¤
   - é¿å…"ä»¥ä¸Šçš†æ˜¯"æˆ–"ä»¥ä¸Šçš†é"çš„é¸é …
   - é¸é …é•·åº¦ç›¸è¿‘ï¼Œé¿å…æ˜é¡¯æç¤º

3. **è©•ä¼°æ•ˆæœ**
   - èƒ½æœ‰æ•ˆæ¸¬è©¦å­¸ç¿’æˆæœ
   - è¦†è“‹é‡è¦æ¦‚å¿µå’Œç´°ç¯€
   - æ”¯æŒè‡ªæˆ‘è©•ä¼°å’Œå¾©ç¿’
   - æä¾›å­¸ç¿’åé¥‹

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

**æ ¼å¼è¦æ±‚ï¼š**
è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å« 5 é“é¸æ“‡é¡Œï¼š

[
  {{
    "question": "å•é¡Œå…§å®¹",
    "options": ["Aé¸é …", "Bé¸é …", "Cé¸é …", "Dé¸é …"],
    "correct": "A",
    "explanation": "ç‚ºä»€éº¼é€™å€‹ç­”æ¡ˆæ­£ç¢ºçš„è©³ç´°è§£é‡‹"
  }}
]

åŸºæ–¼ä»¥ä¸‹ç­†è¨˜å…§å®¹å‰µå»ºæ¸¬é©—ï¼š
{notes}
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2500,  # Increased for comprehensive quizzes
                temperature=0.5
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Failed to generate quiz: {str(e)}")

    def generate_unified_notes(self, content, detail_level='medium', language='zh-tw', context_info=None):
        """Generate notes from multiple unified sources with enhanced context awareness"""
        
        if not context_info:
            context_info = {}
        
        # ThetaWave å°ˆæ¥­è©³ç´°åº¦è¦æ ¼
        detail_instructions = {
            'brief': """ğŸ“ ç°¡æ½”ç‰ˆ (Quick Review Notes) - ç›®æ¨™ï¼š<500å­—ï¼Œ2åˆ†é˜é–±è®€

**æ ¼å¼è¦æ±‚ï¼š**
â€¢ å…¨ç¨‹ä½¿ç”¨é …ç›®ç¬¦è™Ÿ
â€¢ å®šç¾©é™åˆ¶ä¸€è¡Œå…§
â€¢ åˆ—å‡ºä¸»è¦æ¦‚å¿µï¼Œç„¡éœ€è©³è¿°
â€¢ åªåŒ…å«æœ€é‡è¦çš„å…¬å¼/æ–¹ç¨‹å¼
â€¢ æ¯æ¦‚å¿µæœ€å¤š1-2å¥è©±

**å¿…é ˆåŒ…å«ï¼š**
- æ ¸å¿ƒæ¦‚å¿µï¼ˆåƒ…åç¨±ï¼‰
- åŸºæœ¬å®šç¾©ï¼ˆ10å­—å…§ï¼‰
- é—œéµå…¬å¼
- ä¸»è¦åˆ†é¡/é¡å‹
- é‡è¦è¦å‰‡ï¼ˆç„¡ä¾‹å¤–ï¼Œé™¤éæ¥µé—œéµï¼‰

**çµ•å°æ’é™¤ï¼š**
- è©³ç´°è§£é‡‹
- é€æ­¥éç¨‹
- å¤šå€‹ä¾‹å­
- èƒŒæ™¯è³‡è¨Š
- è¡¨æ ¼å’Œæ¯”è¼ƒ

**è¼¸å‡ºæ ¼å¼ï¼š**
ä¸»é¡Œåç¨±
â€¢ é‡é»1
â€¢ é‡é»2
â€¢ å…¬å¼ï¼š[å…¬å¼]
â€¢ é‡è¦è¦å‰‡ï¼š[ç°¡çŸ­é™³è¿°]

é©åˆï¼šå¿«é€Ÿè¤‡ç¿’ã€è€ƒå‰æƒæã€é‡é»æ•´ç†""",
            
            'medium': """ğŸ“š é©ä¸­ç‰ˆ (Standard Study Notes) - ç›®æ¨™ï¼š800-1200å­—ï¼Œ5-7åˆ†é˜é–±è®€

**çµæ§‹è¦æ±‚ï¼š**
ğŸ“Œ æ¸…æ¥šæ¨™é¡Œçš„ä¸»è¦ç« ç¯€
â€¢ é—œéµæ¦‚å¿µçš„é …ç›®ç¬¦è™Ÿ
â€¢ ç°¡è¦è§£é‡‹ï¼ˆ2-3å¥è©±ï¼‰
â€¢ æ¯ä¸»è¦æ¦‚å¿µä¸€å€‹ä¾‹å­
â€¢ æ¯”è¼ƒç”¨çš„ç°¡å–®è¡¨æ ¼

**å…§å®¹æ·±åº¦ï¼š**
- å®šç¾©æ‰€æœ‰é‡è¦è¡“èª
- è§£é‡‹æ ¸å¿ƒéç¨‹ï¼ˆæ¦‚è¦½å±¤æ¬¡ï¼‰
- åŒ…å«ä¸»è¦ä¾‹å­åŠç°¡è¦åˆ†æ
- é™³è¿°è¦å‰‡åŠä¸»è¦ä¾‹å¤–
- é¡¯ç¤ºé‡è¦é—œä¿‚

**æ ¼å¼è¦æ±‚ï¼š**
1. **æ¦‚å¿µåç¨±**
   - å®šç¾©ï¼šæ¸…æ¥šã€å®Œæ•´å¥å­
   - é—œéµç‰¹å¾µæˆ–åŸç†
   - ä¸€å€‹ç›¸é—œä¾‹å­

2. **å°æ–¼éç¨‹ï¼š**
   - ç™¼ç”Ÿä»€éº¼ï¼ˆæ¦‚æ‹¬æè¿°ï¼‰
   - é—œéµæ­¥é©Ÿï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
   - ä¸€å€‹å¯¦ä½œä¾‹å­

3. **å¿…é ˆåŒ…å«ï¼š**
   - ç« ç¯€æ‘˜è¦
   - é‡è¦å…¬å¼åŠæ¨™ç±¤
   - å¿«é€Ÿè­˜åˆ¥æŠ€å·§
   - å›°é›£æ¦‚å¿µçš„è¨˜æ†¶è¼”åŠ©

é©åˆï¼šæ—¥å¸¸å­¸ç¿’ã€ä½œæ¥­æº–å‚™ã€ç†è§£æ¦‚å¿µ""",
            
            'detailed': """ğŸ“– è©³ç´°ç‰ˆ (Comprehensive Learning Material) - ç›®æ¨™ï¼š2000+å­—ï¼Œ15-20åˆ†é˜é–±è®€

**å®Œæ•´çµæ§‹è¦æ±‚ï¼š**
ğŸ” ä¸»è¦ç« ç¯€ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿåœ–ç¤º
### æ¸…æ¥šçš„éšå±¤æ¨™é¡Œ (H1, H2, H3)
- å¤šå±¤æ¬¡é …ç›®ç¬¦è™Ÿ
- ç¨‹åºç”¨ç·¨è™Ÿåˆ—è¡¨
- **ç²—é«”**æ¨™ç¤ºæ‰€æœ‰é—œéµè¡“èª
- *æ–œé«”*å¼·èª¿

**æ¯å€‹æ¦‚å¿µçš„å®Œæ•´è¦æ ¼ï¼š**
- å®Œæ•´å®šç¾©åŠèƒŒæ™¯
- é‹ä½œæ–¹å¼çš„è©³ç´°è§£é‡‹
- é‡è¦æ€§èªªæ˜
- å¤šå€‹ä¾‹å­åŠå®Œæ•´åˆ†æ
- å¸¸è¦‹èª¤è§£
- ç›¸é—œæ¦‚å¿µ

**æ¯å€‹éç¨‹çš„è©³ç´°è¦æ±‚ï¼š**
- é€æ­¥åˆ†è§£
- åˆ†å­å±¤æ¬¡ç™¼ç”Ÿçš„äº‹
- å®Œæ•´å¯¦ä½œä¾‹å­
- è®ŠåŒ–å’Œç‰¹æ®Šæƒ…æ³
- è¦–è¦ºæè¿°

**è¡¨æ ¼æ ¼å¼ï¼š**
| æ–¹é¢ | æè¿° | ä¾‹å­ | ç‰¹æ®Šè¨»è¨˜ |
|------|------|------|----------|
| [åŒ…å«æ‰€æœ‰ç›¸é—œæ¯”è¼ƒ] |

**ä¾‹å­æ ¼å¼ï¼š**
### ä¾‹å­ [#]ï¼š[æè¿°æ€§æ¨™é¡Œ]

**çµ¦å®šåæ‡‰ï¼š** [å®Œæ•´æ–¹ç¨‹å¼]

**é€æ­¥åˆ†æï¼š**
1. åˆå§‹ç‹€æ…‹ï¼š[è©³ç´°æè¿°]
2. éç¨‹ï¼š[ä»€éº¼æ”¹è®ŠåŠç‚ºä»€éº¼]
3. é›»å­è½‰ç§»ï¼š[é¡¯ç¤ºæ–¹ç¨‹å¼]

**æ°§åŒ–æ…‹ï¼š**
- å…ƒç´ Aï¼š[åˆå§‹] â†’ [æœ€çµ‚] (è®ŠåŒ–ï¼š+/- X)
- å…ƒç´ Bï¼š[åˆå§‹] â†’ [æœ€çµ‚] (è®ŠåŒ–ï¼š+/- X)

**é—œéµæ´å¯Ÿï¼š** [é‡è¦æ”¶ç©«]

**ç‰¹æ®Šç« ç¯€ï¼š**
ğŸ“Š **å¿«é€Ÿåƒè€ƒæ¡†**
ğŸ’¡ **å°ˆæ¥­æŠ€å·§** 
âš ï¸ **é‡è¦ä¾‹å¤–**
ğŸ”¬ **æ·±åº¦ç†è§£**

**æ·±åº¦æŒ‡æ¨™ï¼š**
âœ… åŒ…å«ä¾†æºçš„ALLä¾‹å­
âœ… é¡¯ç¤ºå®Œæ•´åŒ–å­¸æ–¹ç¨‹å¼åŠç‹€æ…‹
âœ… è§£é‡‹é›»å­å±¤æ¬¡æ©Ÿåˆ¶
âœ… åŒ…å«æ•¸å­¸æ¨å°ï¼ˆå¦‚ç›¸é—œï¼‰

è¼¸å‡ºæ‡‰è©²è©³ç›¡åˆ°å¯ä»¥å–ä»£åŸå§‹å…§å®¹ã€‚
é©åˆï¼šæ·±åº¦å­¸ç¿’ã€æ•™å­¸æº–å‚™ã€å®Œæ•´ç†è§£"""
        }
        
        # Enhanced language-specific instructions
        language_instructions = {
            'en': "Create comprehensive unified study notes in English from multiple sources. Integrate all content seamlessly while maintaining academic quality.",
            'zh-cn': "è¯·ä»å¤šä¸ªæ¥æºåˆ›å»ºå…¨é¢ç»Ÿä¸€çš„ç®€ä½“ä¸­æ–‡å­¦ä¹ ç¬”è®°ã€‚æ— ç¼æ•´åˆæ‰€æœ‰å†…å®¹ï¼Œä¿æŒå­¦æœ¯è´¨é‡ã€‚",
            'zh-tw': "è«‹å¾å¤šå€‹ä¾†æºå‰µå»ºå…¨é¢çµ±ä¸€çš„ç¹é«”ä¸­æ–‡å­¸ç¿’ç­†è¨˜ã€‚ç„¡ç¸«æ•´åˆæ‰€æœ‰å…§å®¹ï¼Œä¿æŒå­¸è¡“è³ªé‡ã€‚"
        }
        
        detail_instruction = detail_instructions.get(detail_level, detail_instructions['medium'])
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        # Context-aware prompt enhancement
        exam_context = ""
        if context_info.get('exam_system'):
            exam_system_names = {
                'ibdp': 'IB Diploma Programme',
                'al': 'A Level',
                'gcse': 'GCSE',
                'hkdse': 'HKDSE',
                'ap': 'Advanced Placement',
                'sat': 'SAT'
            }
            exam_name = exam_system_names.get(context_info['exam_system'], context_info['exam_system'])
            exam_context = f"é‡å° {exam_name} è€ƒè©¦ç³»çµ±"
        
        subject_context = ""
        if context_info.get('subject'):
            subject_names = {
                'chemistry': 'åŒ–å­¸',
                'physics': 'ç‰©ç†',
                'biology': 'ç”Ÿç‰©',
                'pure-mathematics': 'ç´”æ•¸å­¸',
                'computer-science': 'è¨ˆç®—æ©Ÿç§‘å­¸'
            }
            subject_name = subject_names.get(context_info['subject'], context_info['subject'])
            subject_context = f"ï¼Œç§‘ç›®ï¼š{subject_name}"
        
        topic_context = ""
        if context_info.get('topic') or context_info.get('custom_topic'):
            topic = context_info.get('custom_topic') or context_info.get('topic', '')
            topic_context = f"ï¼Œä¸»é¡Œï¼š{topic}"
        
        source_context = ""
        if context_info.get('sources'):
            source_types = [s['type'] for s in context_info['sources']]
            source_counts = {}
            for source_type in source_types:
                source_counts[source_type] = source_counts.get(source_type, 0) + 1
            
            source_descriptions = []
            for source_type, count in source_counts.items():
                type_names = {
                    'youtube': 'YouTube å½±ç‰‡',
                    'file': 'æ–‡ä»¶',
                    'text': 'æ–‡å­—å…§å®¹',
                    'webpage': 'ç¶²é '
                }
                type_name = type_names.get(source_type, source_type)
                source_descriptions.append(f"{count}å€‹{type_name}")
            
            source_context = f"ï¼Œæ•´åˆä¾†æºï¼š{', '.join(source_descriptions)}"

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¤šæºå­¸ç¿’å…§å®¹æ•´åˆå°ˆå®¶ã€‚{language_instruction}

## ä»»å‹™èƒŒæ™¯ï¼š
{exam_context}{subject_context}{topic_context}{source_context}

## è©³ç´°ç¨‹åº¦è¦æ±‚ï¼š
{detail_instruction}

## å…§å®¹æ•´åˆè¦æ±‚ï¼š

### ğŸ¯ æ•´åˆåŸå‰‡ï¼š
1. **çµ±ä¸€æ€§** - å°‡æ‰€æœ‰ä¾†æºçš„å…§å®¹æ•´åˆç‚ºä¸€å€‹é€£è²«çš„å­¸ç¿’è³‡æº
2. **å±¤æ¬¡æ€§** - æŒ‰é‡è¦æ€§å’Œé‚è¼¯é †åºçµ„ç¹”å…§å®¹
3. **å®Œæ•´æ€§** - ä¿ç•™æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œé¿å…é‡è¤‡å’Œå†—é¤˜
4. **å­¸ç¿’å°å‘** - é‡å°{exam_context}çš„å­¸ç¿’å’Œè€ƒè©¦éœ€æ±‚å„ªåŒ–

### ğŸ“š ç­†è¨˜çµæ§‹è¦æ±‚ï¼š
1. **ğŸ¯ æ¦‚è¦½/ä»‹ç´¹** - ä¸»é¡Œç¸½è¦½å’Œå­¸ç¿’ç›®æ¨™
2. **ğŸ§  æ ¸å¿ƒæ¦‚å¿µ** - æ‰€æœ‰é—œéµæ¦‚å¿µçš„å®Œæ•´è§£é‡‹
3. **âš™ï¸ è©³ç´°æ©Ÿåˆ¶/éç¨‹** - é€æ­¥éç¨‹å’Œé‹ä½œæ–¹å¼
4. **ğŸ“ å¯¦ä¾‹åˆ†æ** - å¤šå€‹å®Œæ•´ä¾‹å­çš„è©³ç´°è§£æ
5. **âš ï¸ ç‰¹æ®Šæƒ…æ³** - ä¾‹å¤–æƒ…æ³å’Œæ³¨æ„äº‹é …
6. **ğŸ“‹ å¿«é€Ÿåƒè€ƒ** - ç¸½çµè¡¨æ ¼å’Œé—œéµå…¬å¼
7. **ğŸ” å­¸ç¿’æŠ€å·§** - è¨˜æ†¶æ–¹æ³•å’Œè­˜åˆ¥æŠ€å·§

### ğŸ” æ ¼å¼è¦æ±‚ï¼š

#### 1. çµæ§‹èˆ‡æ ¼å¼åŒ–
- ä½¿ç”¨æ¸…æ™°çš„è¡¨æƒ…ç¬¦è™Ÿåœ–æ¨™æ¨™ç¤ºä¸»è¦ç« ç¯€ (ğŸ”„, ğŸ§ª, ğŸ“Š, âš—ï¸, ğŸ“ˆ, ğŸ’¡ç­‰)
- å‰µå»ºå¤šå±¤æ¬¡æ¨™é¡Œçµæ§‹ (H1, H2, H3, H4)
- ç‚ºæ¯”è¼ƒå’Œé—œä¿‚å‰µå»ºè¡¨æ ¼
- ä½¿ç”¨é …ç›®ç¬¦è™Ÿåˆ—è¡¨
- **ç²—é«”**æ¨™ç¤ºé—œéµè¡“èªå’Œå®šç¾©
- åŒ…å«ç›¸é—œçš„å…¬å¼/æ–¹ç¨‹å¼

#### 2. å…§å®¹æ·±åº¦è¦æ±‚
- æä¾›**å®Œæ•´**è§£é‡‹ï¼Œè€Œéåƒ…åƒ…ç¸½çµ
- åŒ…å«æºå…§å®¹ä¸­æåŠçš„**æ‰€æœ‰**ä¾‹å­
- é¡¯ç¤ºé€æ­¥éç¨‹
- åŒ…å«å…·é«”æ•¸å­—ã€å…¬å¼å’Œæ•¸æ“š
- è§£é‡‹æ¦‚å¿µèƒŒå¾Œçš„"ç‚ºä»€éº¼"ï¼Œä¸åªæ˜¯"æ˜¯ä»€éº¼"

#### 3. å¿…é ˆåŒ…å«çš„å…§å®¹é¡å‹

**å°æ–¼æ¦‚å¿µï¼š**
- å®Œæ•´å®šç¾©
- é‹ä½œæ–¹å¼
- é‡è¦æ€§åŸå› 
- ç›¸é—œæ¦‚å¿µ
- å¸¸è¦‹èª¤è§£

**å°æ–¼éç¨‹ï¼š**
- æ¯å€‹æ­¥é©Ÿçš„è©³ç´°è§£é‡‹
- æ¯å€‹éšæ®µç™¼ç”Ÿä»€éº¼
- å¸¸è¦‹è®ŠåŒ–
- æ¢ä»¶å’Œé™åˆ¶

**å°æ–¼ä¾‹å­ï¼š**
- å®Œæ•´çš„æ–¹ç¨‹å¼/å…¬å¼
- é€æ­¥åˆ†æ
- è­˜åˆ¥æ‰€æœ‰çµ„æˆéƒ¨åˆ†
- è§£é‡‹çµæœ
- æ‡‰ç”¨å ´æ™¯

#### 4. è¡¨æ ¼æ ¼å¼ç¯„ä¾‹
```
| æ¦‚å¿µ/ç‰¹å¾µ | å®šç¾©/èªªæ˜ | ä¾‹å­/æ‡‰ç”¨ | æ³¨æ„äº‹é … |
|----------|----------|----------|----------|
| é …ç›®A | è©³ç´°èªªæ˜A | å…·é«”ä¾‹å­A | ç‰¹æ®Šæƒ…æ³A |
| é …ç›®B | è©³ç´°èªªæ˜B | å…·é«”ä¾‹å­B | ç‰¹æ®Šæƒ…æ³B |
```

#### 5. ä¾‹å­æ ¼å¼ç¯„ä¾‹
```
### ğŸ”¬ ä¾‹å­X: [å…·é«”æ¨™é¡Œ]
**èƒŒæ™¯ï¼š** [æƒ…æ³æè¿°]
**æ­¥é©Ÿåˆ†æï¼š**
1. **æ­¥é©Ÿ1ï¼š** [è©³ç´°è§£é‡‹ç™¼ç”Ÿä»€éº¼]
2. **æ­¥é©Ÿ2ï¼š** [ç‚ºä»€éº¼æœƒé€™æ¨£è®ŠåŒ–]
3. **æ­¥é©Ÿ3ï¼š** [æœ€çµ‚çµæœå¦‚ä½•ç”¢ç”Ÿ]

**é—œéµè­˜åˆ¥é»ï¼š**
- ç‰¹å¾µA: [å¦‚ä½•è­˜åˆ¥å’Œæ„ç¾©]
- ç‰¹å¾µB: [å¦‚ä½•è­˜åˆ¥å’Œæ„ç¾©]

**çµæœè§£é‡‹ï¼š** [ç‚ºä»€éº¼æœƒæœ‰é€™å€‹çµæœï¼Œæ„ç¾©æ˜¯ä»€éº¼]
```

### ğŸ“Š å“è³ªæ¨™æº–ï¼š
- âœ… æ²’çœ‹éåŸå…§å®¹çš„äººæ‡‰è©²å®Œå…¨ç†è§£ä¸»é¡Œ
- âœ… è¶³å¤ è©³ç´°ç”¨æ–¼è€ƒè©¦æº–å‚™  
- âœ… é©åˆåˆå­¸å’Œå¾©ç¿’é›™é‡ç”¨é€”
- âœ… åŒ…å«å…·é«”å…¬å¼ã€æ•¸æ“šã€è¨ˆç®—
- âœ… è§£é‡‹æ¦‚å¿µé–“é—œä¿‚å’Œè¯ç¹«
- âœ… æä¾›è¨˜æ†¶è¼”åŠ©å’Œæ¨¡å¼è­˜åˆ¥
- âœ… çµ•ä¸ä½¿ç”¨ç¸®ç•¥è§£é‡‹ - å¿…é ˆå¾¹åº•å®Œæ•´

### ğŸš« é¿å…äº‹é …ï¼š
- ä¸è¦åªæ˜¯åˆ—å‡ºè¦é»ï¼Œè¦å®Œæ•´è§£é‡‹
- ä¸è¦è·³éä¾‹å­çš„è©³ç´°åˆ†æ
- ä¸è¦ä½¿ç”¨"ç­‰ç­‰"ã€"è«¸å¦‚æ­¤é¡"ç­‰çœç•¥èª
- ä¸è¦å‡è¨­è®€è€…å·²æœ‰èƒŒæ™¯çŸ¥è­˜

è«‹åŸºæ–¼ä»¥ä¸Šè©³ç´°è¦æ±‚ï¼Œå°‡æä¾›çš„å¤šæºå…§å®¹æ•´åˆç‚ºé«˜è³ªé‡ã€è¶…è©³ç´°çš„çµ±ä¸€å­¸ç¿’ç­†è¨˜ï¼š

---

{content}

---

è«‹å‰µå»ºä¸€ä»½å¾¹åº•å®Œæ•´ã€é©åˆæ·±åº¦å­¸ç¿’çš„å°ˆæ¥­ç­†è¨˜ã€‚"""

        # æ ¹æ“šè©³ç´°ç¨‹åº¦è¨­ç½®é©ç•¶çš„ token é™åˆ¶
        token_limits = {
            'brief': 800,      # <500å­—ç›®æ¨™
            'medium': 2000,    # 800-1200å­—ç›®æ¨™  
            'detailed': 8000   # 2000+å­—ç›®æ¨™
        }
        max_tokens = token_limits.get(detail_level, 2000)
        
        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": language_instruction},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating unified notes: {e}")
            return "æŠ±æ­‰ï¼Œç”Ÿæˆçµ±ä¸€ç­†è¨˜æ™‚å‡ºç¾éŒ¯èª¤ã€‚"