import openai
from config import Config

class OpenAIService:
    def __init__(self):
        openai.api_key = Config.OPENAI_API_KEY
        self.model = Config.OPENAI_MODEL
        
    def generate_notes(self, content, detail_level='medium', language='zh-tw', content_type='general'):
        """Generate notes from content using OpenAI with enhanced prompts and smart content handling"""
        
        # Handle very large content by intelligent chunking if needed
        if len(content) > 15000:  # ~15k characters is roughly safe limit for context
            return self._generate_notes_chunked(content, detail_level, language, content_type)
        
        # Get optimized prompt based on detail level, language, and content type
        prompt = self._create_prompt(content, detail_level, language, content_type)
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "You are an expert note-taker who creates well-structured study notes in Markdown format. Provide content directly without meta-commentary or conclusive summaries."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=Config.OPENAI_MAX_TOKENS,
                temperature=Config.OPENAI_TEMPERATURE
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Failed to generate notes: {str(e)}")
    
    def _generate_notes_chunked(self, content, detail_level, language, content_type):
        """Handle very large content by chunking and combining results"""
        
        # Split content into manageable chunks
        chunk_size = 12000  # Safe chunk size
        chunks = []
        
        for i in range(0, len(content), chunk_size):
            chunk = content[i:i + chunk_size]
            chunks.append(chunk)
        
        # Generate notes for each chunk
        chunk_notes = []
        for i, chunk in enumerate(chunks):
            try:
                prompt = self._create_prompt(chunk, detail_level, language, content_type)
                
                # Add chunk context
                if len(chunks) > 1:
                    prompt += f"\n\næ³¨æ„ï¼šé€™æ˜¯ç¬¬ {i+1} éƒ¨åˆ†ï¼Œå…± {len(chunks)} éƒ¨åˆ†ã€‚è«‹ç¢ºä¿å…§å®¹éŠœæ¥è‡ªç„¶ã€‚ä¸è¦æ·»åŠ ç¸½çµæ€§çµå°¾ï¼Œç›´æ¥ä»¥å…§å®¹çµæŸã€‚"
                
                response = openai.ChatCompletion.create(
                    model=Config.OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": "You are an expert note-taker who creates well-structured study notes in Markdown format. Provide content directly without meta-commentary or conclusive summaries."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=Config.OPENAI_MAX_TOKENS,
                    temperature=Config.OPENAI_TEMPERATURE
                )
                
                chunk_notes.append(response.choices[0].message.content)
                
            except Exception as e:
                chunk_notes.append(f"## ç¬¬ {i+1} éƒ¨åˆ†è™•ç†éŒ¯èª¤\n\néŒ¯èª¤: {str(e)}")
        
        # Combine all chunk notes
        if len(chunk_notes) == 1:
            return chunk_notes[0]
        
        # Create a unified document from chunks
        combined_notes = "# å®Œæ•´å­¸ç¿’ç­†è¨˜\n\n"
        for i, notes in enumerate(chunk_notes):
            # Remove duplicate headers and combine
            clean_notes = notes.replace("# ", "## ").replace("##", f"## ç¬¬ {i+1} éƒ¨åˆ† - ")
            combined_notes += clean_notes + "\n\n---\n\n"
        
        return combined_notes.rstrip("\n---\n")
    
    def _create_prompt(self, content, detail_level, language='zh-tw', content_type='general'):
        """Create optimized prompt for note generation based on Claude Opus 4.1 suggestions"""
        
        # Enhanced detail level instructions
        detail_instructions = {
            'brief': """å°ˆæ³¨æ–¼æœ€æ ¸å¿ƒçš„æ¦‚å¿µå’Œè¦é»ã€‚å‰µå»ºç°¡æ½”ä½†å®Œæ•´çš„ç­†è¨˜ï¼š
- åªåŒ…å«å¿…é ˆæŒæ¡çš„é—œéµæ¦‚å¿µ
- æ¯å€‹ä¸»é¡Œé™åˆ¶åœ¨æœ€é‡è¦çš„2-3å€‹è¦é»
- ä½¿ç”¨ç°¡æ½”çš„èªè¨€ï¼Œé¿å…å†—é¤˜
- é©åˆå¿«é€Ÿå¾©ç¿’å’Œæ¦‚è¦½
- ä¿æŒé‚è¼¯æ¸…æ™°ä½†å…§å®¹ç²¾ç°¡""",
            
            'medium': """å‰µå»ºå¹³è¡¡ä½†å…¨é¢çš„è©³ç´°ç­†è¨˜ï¼š
ã€æ ¸å¿ƒè¦æ±‚ã€‘
- åŒ…å«æ‰€æœ‰ä¸»è¦æ¦‚å¿µçš„å®Œæ•´è§£é‡‹
- æä¾›é—œéµä¾‹å­çš„è©³ç´°åˆ†æ
- åŒ…å«é‡è¦çš„å…¬å¼ã€æ•¸æ“šå’Œæ­¥é©Ÿ
- è§£é‡‹æ¦‚å¿µé–“çš„é—œä¿‚å’Œé€£çµ

ã€è©³ç´°ç¨‹åº¦ã€‘
- æ¯å€‹æ¦‚å¿µéƒ½è¦æœ‰å……åˆ†çš„è§£é‡‹
- åŒ…å«è‡³å°‘2-3å€‹å…¸å‹ä¾‹å­
- æä¾›å¯¦ç”¨çš„è­˜åˆ¥æ–¹æ³•å’ŒæŠ€å·§
- é©åˆæ·±åº¦å­¸ç¿’ï¼Œä¸åªæ˜¯æ¦‚è¦½""",
            
            'detailed': """å‰µå»ºæ¥µå…¶è©³ç›¡ã€å…¨é¢çš„å­¸ç¿’ç­†è¨˜ï¼š
ã€å®Œæ•´æ€§è¦æ±‚ã€‘
- åŒ…å«æºå…§å®¹ä¸­çš„ALLä¿¡æ¯ï¼Œä¸éºæ¼ä»»ä½•ç´°ç¯€
- æä¾›COMPLETEè§£é‡‹ï¼Œä¸åªæ˜¯ç¸½çµ
- åŒ…å«æ‰€æœ‰æåŠçš„ä¾‹å­ã€æ•¸æ“šã€å…¬å¼ã€æ­¥é©Ÿ
- è§£é‡‹"ç‚ºä»€éº¼"ï¼Œä¸åªæ˜¯"æ˜¯ä»€éº¼"

ã€è©³ç´°ç¨‹åº¦æ¨™æº–ã€‘
- æ²’çœ‹éåŸå…§å®¹çš„äººæ‡‰è©²å®Œå…¨ç†è§£ä¸»é¡Œ
- è¶³å¤ è©³ç´°ç”¨æ–¼è€ƒè©¦æº–å‚™
- é©åˆåˆå­¸å’Œå¾©ç¿’é›™é‡ç”¨é€”
- çµ•ä¸ä½¿ç”¨ç¸®ç•¥è§£é‡‹ - å¿…é ˆå¾¹åº•å®Œæ•´"""
        }
        
        # Enhanced language-specific instructions
        language_instructions = {
            'en': "Create comprehensive study notes in English. Use clear, academic English suitable for learning and review. Ensure professional terminology and proper grammar throughout.",
            'zh-cn': "è¯·ç”¨ç®€ä½“ä¸­æ–‡åˆ›å»ºå…¨é¢çš„å­¦ä¹ ç¬”è®°ã€‚ä½¿ç”¨æ¸…æ™°ã€å­¦æœ¯åŒ–çš„ä¸­æ–‡è¡¨è¾¾ï¼Œé€‚åˆå­¦ä¹ å’Œå¤ä¹ ã€‚ç¡®ä¿ä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼Œè¯­æ³•è§„èŒƒã€‚",
            'zh-tw': "è«‹ç”¨ç¹é«”ä¸­æ–‡å‰µå»ºå…¨é¢çš„å­¸ç¿’ç­†è¨˜ã€‚ä½¿ç”¨æ¸…æ™°ã€å­¸è¡“åŒ–çš„ä¸­æ–‡è¡¨é”ï¼Œé©åˆå­¸ç¿’å’Œè¤‡ç¿’ã€‚ç¢ºä¿å°ˆæ¥­è¡“èªæº–ç¢ºï¼Œèªæ³•è¦ç¯„ã€‚"
        }
        
        # Content-type specific instructions
        content_type_instructions = {
            'youtube': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸ç¿’ç­†è¨˜å°ˆå®¶ã€‚è«‹å¾æä¾›çš„ YouTube å½±ç‰‡è½‰éŒ„æ–‡æœ¬å‰µå»ºé«˜è³ªé‡çš„å­¸ç¿’ç­†è¨˜ã€‚

## åˆ†ææ–¹æ³•ï¼š
1. **å®Œæ•´ç†è§£å…§å®¹** - ä»”ç´°é–±è®€æ•´å€‹è½‰éŒ„æ–‡æœ¬ï¼Œè­˜åˆ¥ä¸»è¦æ¦‚å¿µå’Œé—œéµä¿¡æ¯ï¼Œéæ¿¾æ‰å¡«å……è©ã€é‡è¤‡å…§å®¹å’Œéæ•™è‚²æ€§å…§å®¹
2. **çµæ§‹åŒ–çµ„ç¹”** - æŒ‰ä¸»é¡Œè€Œéæ™‚é–“é †åºçµ„ç¹”ï¼Œå¾åŸºç¤æ¦‚å¿µåˆ°é€²éšå…§å®¹ï¼Œå‰µå»ºæ¸…æ™°çš„å±¤æ¬¡çµæ§‹
3. **å…§å®¹è¦æ±‚** - åŒ…å«æ‰€æœ‰é‡è¦ä¿¡æ¯é»ï¼Œä¿ç•™å…·é«”ä¾‹å­å’Œæ•¸æ“šï¼Œçªå‡ºé—œéµè¡“èªå’Œå®šç¾©""",
            
            'pdf': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å­¸è¡“ç­†è¨˜æ•´ç†å°ˆå®¶ã€‚è«‹å°‡æä¾›çš„ PDF æ–‡æœ¬å…§å®¹è½‰æ›ç‚ºçµæ§‹åŒ–çš„å­¸ç¿’ç­†è¨˜ã€‚

## è™•ç†ç­–ç•¥ï¼š
1. **æ–‡æœ¬åˆ†æ** - è­˜åˆ¥ç« ç¯€çµæ§‹å’Œä¸»è¦è«–é»ï¼Œæå–é—œéµæ¦‚å¿µã€å®šç¾©å’Œç†è«–ï¼Œä¿ç•™é‡è¦çš„æ•¸æ“šã€çµ±è¨ˆå’Œå¼•ç”¨
2. **çŸ¥è­˜æ•´åˆ** - æŒ‰æ¦‚å¿µä¸»é¡Œé‡æ–°çµ„ç¹”å…§å®¹ï¼Œå»ºç«‹æ¦‚å¿µä¹‹é–“çš„é‚è¼¯è¯ç¹«ï¼Œçªå‡ºé‡è¦çš„å­¸è¡“è¦é»
3. **å­¸ç¿’å„ªåŒ–** - ç°¡åŒ–è¤‡é›œå¥å­ä½†ä¿ç•™åŸæ„ï¼Œæ·»åŠ é‚è¼¯é€£æ¥è©å¢å¼·å¯è®€æ€§ï¼Œå¼·èª¿å¯è€ƒè©¦çš„é‡é»å…§å®¹""",
            
            'general': """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹çµ„ç¹”å°ˆå®¶ã€‚è«‹å°‡æä¾›çš„æ–‡æœ¬å…§å®¹è½‰æ›ç‚ºçµæ§‹åŒ–çš„å­¸ç¿’ç­†è¨˜ã€‚

## è™•ç†æµç¨‹ï¼š
1. **å…§å®¹ç†è§£** - å…¨é¢åˆ†ææ–‡æœ¬çµæ§‹å’Œæ ¸å¿ƒä¸»é¡Œï¼Œè­˜åˆ¥ä¸»è¦è«–é»å’Œæ”¯æŒä¿¡æ¯
2. **çµæ§‹é‡çµ„** - æŒ‰é‚è¼¯ä¸»é¡Œé‡æ–°æ’åˆ—å…§å®¹ï¼Œå‰µå»ºæ¸…æ™°çš„ä¿¡æ¯å±¤æ¬¡ï¼Œå»ºç«‹æ¦‚å¿µé–“çš„é—œè¯
3. **å­¸ç¿’å°å‘** - å„ªåŒ–å…§å®¹ä»¥ä¾¿ç†è§£å’Œè¨˜æ†¶ï¼Œå¼·èª¿å¯æ“ä½œçš„çŸ¥è­˜é»ï¼Œé©åˆä¸åŒå­¸ç¿’é¢¨æ ¼"""
        }
        
        detail_instruction = detail_instructions.get(detail_level, detail_instructions['medium'])
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        content_instruction = content_type_instructions.get(content_type, content_type_instructions['general'])
        
        prompt = f"""
{content_instruction}

## è©³ç´°ç¨‹åº¦è¦æ±‚ï¼š
{detail_instruction}

## æ ¼å¼è¦æ±‚ï¼š

### 1. çµæ§‹èˆ‡æ ¼å¼åŒ–
- ä½¿ç”¨æ¸…æ™°çš„è¡¨æƒ…ç¬¦è™Ÿåœ–æ¨™æ¨™ç¤ºä¸»è¦ç« ç¯€ (ğŸ”„, ğŸ§ª, ğŸ“Š, âš—ï¸, ğŸ“ˆ, ğŸ’¡ç­‰)
- å‰µå»ºå¤šå±¤æ¬¡æ¨™é¡Œçµæ§‹ (H1, H2, H3, H4)
- ç‚ºæ¯”è¼ƒå’Œé—œä¿‚å‰µå»ºè¡¨æ ¼
- ä½¿ç”¨é …ç›®ç¬¦è™Ÿåˆ—è¡¨
- **ç²—é«”**æ¨™ç¤ºé—œéµè¡“èªå’Œå®šç¾©
- åŒ…å«ç›¸é—œçš„å…¬å¼/æ–¹ç¨‹å¼

### 2. å…§å®¹æ·±åº¦è¦æ±‚
- æä¾›**å®Œæ•´**è§£é‡‹ï¼Œè€Œéåƒ…åƒ…ç¸½çµ
- åŒ…å«æºå…§å®¹ä¸­æåŠçš„**æ‰€æœ‰**ä¾‹å­
- é¡¯ç¤ºé€æ­¥éç¨‹
- åŒ…å«å…·é«”æ•¸å­—ã€å…¬å¼å’Œæ•¸æ“š
- è§£é‡‹æ¦‚å¿µèƒŒå¾Œçš„"ç‚ºä»€éº¼"ï¼Œä¸åªæ˜¯"æ˜¯ä»€éº¼"

### 3. è¦–è¦ºçµ„ç¹”
- ç‚ºç›¸é—œæ¦‚å¿µå‰µå»ºæ¯”è¼ƒè¡¨æ ¼
- ç‚ºé‡è¦å®šç¾©ä½¿ç”¨æ ¼å¼åŒ–æ¡†
- åŒ…å«éç¨‹æµç¨‹åœ– (æ­¥é©Ÿ1 â†’ æ­¥é©Ÿ2 â†’ æ­¥é©Ÿ3)
- åœ¨æ¸…æ™°ç« ç¯€ä¸­åˆ†é›¢ä¾‹å­
- å°é¡ä¼¼å…§å®¹é¡å‹ä½¿ç”¨ä¸€è‡´æ ¼å¼

### 4. å…·é«”åŒ…å«å…§å®¹

**å°æ–¼æ¦‚å¿µï¼š**
- å®Œæ•´å®šç¾©
- é‹ä½œæ–¹å¼
- é‡è¦æ€§åŸå› 
- ç›¸é—œæ¦‚å¿µ

**å°æ–¼éç¨‹ï¼š**
- æ¯å€‹æ­¥é©Ÿçš„è©³ç´°è§£é‡‹
- æ¯å€‹éšæ®µç™¼ç”Ÿä»€éº¼
- å¸¸è¦‹è®ŠåŒ–

**å°æ–¼ä¾‹å­ï¼š**
- å®Œæ•´çš„æ–¹ç¨‹å¼/å…¬å¼
- é€æ­¥åˆ†æ
- è­˜åˆ¥æ‰€æœ‰çµ„æˆéƒ¨åˆ†
- è§£é‡‹çµæœ

**å°æ–¼è¦å‰‡/åŸç†ï¼š**
- æ¸…æ¥šé™³è¿°è¦å‰‡
- åˆ—å‡ºæ‰€æœ‰ä¾‹å¤–
- æä¾›æ‡‰ç”¨ä¾‹å­
- å¸¸è¦‹èª¤è§£

### 5. è¡¨æ ¼æ ¼å¼è¦æ±‚
```
| æ¬„ä½1 | æ¬„ä½2 | æ¬„ä½3 |
|-------|-------|-------|
| æ¦‚å¿µ | å®šç¾© | ä¾‹å­ |
| éç¨‹ | ç™¼ç”Ÿä»€éº¼ | çµæœ |
| æ¯”è¼ƒ | é …ç›®A | é …ç›®B |
```

### 6. ä¾‹å­æ ¼å¼
```
### ä¾‹å­X: [æ¨™é¡Œ]
**çµ¦å®šï¼š** [åˆå§‹æ¢ä»¶]
**éç¨‹ï¼š**
- æ­¥é©Ÿ1: [è©³ç´°è§£é‡‹]
- æ­¥é©Ÿ2: [ä»€éº¼æ”¹è®ŠåŠç‚ºä»€éº¼]

**è­˜åˆ¥ï¼š**
- çµ„æˆ1: [è§’è‰²å’Œè®ŠåŒ–]
- çµ„æˆ2: [è§’è‰²å’Œè®ŠåŒ–]

**çµæœï¼š** [æœ€çµ‚çµæœåŠè§£é‡‹]
```

### 7. å¿…é ˆåŒ…å«çš„é—œéµç« ç¯€
- ğŸ¯ æ¦‚è¦½/ä»‹ç´¹
- ğŸ§  æ ¸å¿ƒæ¦‚å¿µï¼ˆå®Œæ•´è§£é‡‹ï¼‰
- âš™ï¸ è©³ç´°æ©Ÿåˆ¶/éç¨‹
- ğŸ“ å¤šå€‹å®Œæ•´ä¾‹å­
- âš ï¸ ç‰¹æ®Šæƒ…æ³å’Œä¾‹å¤–
- ğŸ“‹ å¿«é€Ÿåƒè€ƒ/ç¸½çµ
- ğŸ” è­˜åˆ¥æ–¹æ³•/æŠ€å·§

## è³ªé‡æ¨™æº–ï¼š
- âœ… æ²’çœ‹éåŸå…§å®¹çš„äººæ‡‰è©²å®Œå…¨ç†è§£ä¸»é¡Œ
- âœ… è¶³å¤ è©³ç´°ç”¨æ–¼è€ƒè©¦æº–å‚™  
- âœ… é©åˆåˆå­¸å’Œå¾©ç¿’é›™é‡ç”¨é€”
- âœ… åŒ…å«å¯¦éš›åŒ–å­¸å…¬å¼ï¼Œä¸åªæ˜¯åç¨±
- âœ… é¡¯ç¤ºæ°§åŒ–æ…‹æ¨™è¨˜ (+2, -1ç­‰)
- âœ… åŒ…å«é›»å­è½‰ç§»æ–¹ç¨‹å¼
- âœ… è§£é‡‹æ¦‚å¿µé–“é—œä¿‚
- âœ… æä¾›è¨˜æ†¶è¼”åŠ©å’Œæ¨¡å¼è­˜åˆ¥
- âœ… çµ•ä¸ä½¿ç”¨ç¸®ç•¥è§£é‡‹ - å¿…é ˆå¾¹åº•å®Œæ•´

**æ ¼å¼è¦æ±‚ï¼š**
- ç›´æ¥æä¾›å­¸ç¿’å…§å®¹ï¼Œä¸è¦æ·»åŠ ç¸½çµæ€§çµå°¾
- ä¸è¦åŒ…å«"é€™äº›ç­†è¨˜æä¾›äº†..."æˆ–"ç†è§£é€™äº›æ¦‚å¿µå¾ˆé‡è¦"ç­‰ç¸½çµèªå¥
- ç­†è¨˜æ‡‰è©²ä»¥å¯¦éš›å…§å®¹çµæŸï¼Œè€Œä¸æ˜¯å…ƒè©•è«–
- ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿå’Œè¡¨æ ¼å¢å¼·è¦–è¦ºæ•ˆæœ
- ç‚ºæ‰€æœ‰ä¾‹å­æä¾›å®Œæ•´çš„é€æ­¥åˆ†æ

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

è«‹å‰µå»ºä¸€ä»½å°ˆæ¥­çš„å­¸ç¿’ç­†è¨˜ï¼Œç›´æ¥æä¾›å­¸ç¿’å…§å®¹ï¼Œç„¡éœ€ç¸½çµæ€§çµå°¾ã€‚

---

**å…§å®¹ä¾†æºï¼š**
{content}
"""
        return prompt
    
    def generate_flashcards(self, notes, count=15, difficulty='medium', types=['definition', 'example'], language='zh-tw'):
        """Generate enhanced flashcards from notes using optimized prompts"""
        
        # Enhanced language-specific instructions for flashcards
        language_instructions = {
            'en': "Create flashcards in English with clear, academic terminology. Design questions that test understanding and memory effectively.",
            'zh-cn': "åˆ›å»ºç®€ä½“ä¸­æ–‡å­¦ä¹ å¡ç‰‡ã€‚è®¾è®¡èƒ½æœ‰æ•ˆæµ‹è¯•ç†è§£å’Œè®°å¿†çš„é—®é¢˜ï¼Œä½¿ç”¨å‡†ç¡®çš„å­¦æœ¯æœ¯è¯­ã€‚",
            'zh-tw': "å‰µå»ºç¹é«”ä¸­æ–‡å­¸ç¿’å¡ç‰‡ã€‚è¨­è¨ˆèƒ½æœ‰æ•ˆæ¸¬è©¦ç†è§£å’Œè¨˜æ†¶çš„å•é¡Œï¼Œä½¿ç”¨æº–ç¢ºçš„å­¸è¡“è¡“èªã€‚"
        }
        
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        # Define card types in different languages
        type_descriptions = {
            'en': {
                'definition': 'Definition/explanation cards',
                'example': 'Example/illustration cards', 
                'application': 'Application/problem-solving cards',
                'comparison': 'Comparison/contrast cards'
            },
            'zh-cn': {
                'definition': 'å®šä¹‰è§£é‡Šç±»å¡ç‰‡',
                'example': 'ä¸¾ä¾‹è¯´æ˜ç±»å¡ç‰‡',
                'application': 'åº”ç”¨ç»ƒä¹ ç±»å¡ç‰‡', 
                'comparison': 'æ¯”è¾ƒåˆ†æç±»å¡ç‰‡'
            },
            'zh-tw': {
                'definition': 'å®šç¾©è§£é‡‹é¡å¡ç‰‡',
                'example': 'èˆ‰ä¾‹èªªæ˜é¡å¡ç‰‡',
                'application': 'æ‡‰ç”¨ç·´ç¿’é¡å¡ç‰‡',
                'comparison': 'æ¯”è¼ƒåˆ†æé¡å¡ç‰‡'
            }
        }
        
        type_desc = type_descriptions.get(language, type_descriptions['zh-tw'])
        selected_types = [type_desc[t] for t in types if t in type_desc]

        prompt = f"""
åŸºæ–¼æä¾›çš„å­¸ç¿’ç­†è¨˜ï¼Œå‰µå»º {count} å¼µé«˜è³ªé‡çš„è¨˜æ†¶å¡ç‰‡ç”¨æ–¼å­¸ç¿’å¾©ç¿’ã€‚

## å¡ç‰‡è¦æ±‚ï¼š
- æ•¸é‡ï¼š{count} å¼µ
- é›£åº¦ï¼š{difficulty}
- åŒ…å«é¡å‹ï¼š{', '.join(selected_types)}

## å¡ç‰‡è¨­è¨ˆåŸå‰‡ï¼š

1. **å•é¡Œè¨­è¨ˆ**
   - é‡å°é—œéµæ¦‚å¿µå‰µå»ºæ˜ç¢ºçš„å•é¡Œ
   - ä½¿ç”¨ä¸åŒé¡å‹çš„å•é¡Œï¼ˆå®šç¾©ã€æ‡‰ç”¨ã€æ¯”è¼ƒç­‰ï¼‰
   - ç¢ºä¿å•é¡Œå…·æœ‰æŒ‘æˆ°æ€§ä½†å¯å›ç­”
   - é¿å…éæ–¼æ¨¡ç³Šæˆ–éæ–¼ç°¡å–®çš„å•é¡Œ

2. **ç­”æ¡ˆè¦æ±‚**
   - æä¾›æº–ç¢ºã€å®Œæ•´çš„ç­”æ¡ˆ
   - åŒ…å«è¶³å¤ çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
   - ä½¿ç”¨æ¸…æ™°çš„è§£é‡‹å’Œä¾‹å­
   - é©åˆè¨˜æ†¶å’Œç†è§£

3. **å­¸ç¿’æ•ˆæœ**
   - æ¶µè“‹ç­†è¨˜ä¸­çš„æ‰€æœ‰é‡è¦æ¦‚å¿µ
   - å¹³è¡¡è¨˜æ†¶å’Œç†è§£é¡å•é¡Œ
   - æ”¯æŒé–“éš”é‡è¤‡å­¸ç¿’æ³•
   - é©åˆè‡ªæˆ‘æ¸¬è©¦

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

**æ ¼å¼è¦æ±‚ï¼š**
è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å« 10 å¼µå¡ç‰‡ï¼š

[
  {{"question": "æ¸…æ™°çš„å•é¡Œ", "answer": "è©³ç´°çš„ç­”æ¡ˆ"}},
  {{"question": "å¦ä¸€å€‹å•é¡Œ", "answer": "å°æ‡‰çš„ç­”æ¡ˆ"}}
]

åŸºæ–¼ä»¥ä¸‹ç­†è¨˜å…§å®¹å‰µå»ºè¨˜æ†¶å¡ç‰‡ï¼š
{notes}
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,  # Increased for better flashcards
                temperature=0.5
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Failed to generate flashcards: {str(e)}")
    
    def generate_quiz(self, notes, language='zh-tw'):
        """Generate quiz from notes"""
        
        # Language-specific instructions for quiz
        language_instructions = {
            'en': "Create quiz questions in English. Make questions educational and clear.",
            'zh-cn': "åˆ›å»ºç®€ä½“ä¸­æ–‡æµ‹éªŒé¢˜ç›®ã€‚é¢˜ç›®è¦æœ‰æ•™è‚²æ„ä¹‰ä¸”æ¸…æ™°ã€‚",
            'zh-tw': "å‰µå»ºç¹é«”ä¸­æ–‡æ¸¬é©—é¡Œç›®ã€‚é¡Œç›®è¦æœ‰æ•™è‚²æ„ç¾©ä¸”æ¸…æ™°ã€‚"
        }
        
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        prompt = f"""
åŸºæ–¼æä¾›çš„å­¸ç¿’ç­†è¨˜ï¼Œå‰µå»ºä¸€å€‹å…¨é¢çš„é¸æ“‡é¡Œæ¸¬é©—ä¾†è©•ä¼°å­¸ç¿’æ•ˆæœã€‚

## æ¸¬é©—è¨­è¨ˆæ¨™æº–ï¼š

1. **é¡Œç›®è³ªé‡**
   - æ¶µè“‹ç­†è¨˜ä¸­çš„é—œéµçŸ¥è­˜é»
   - æ¸¬è©¦ä¸åŒå±¤æ¬¡çš„ç†è§£ï¼ˆè¨˜æ†¶ã€ç†è§£ã€æ‡‰ç”¨ï¼‰
   - å•é¡Œè¡¨è¿°æ¸…æ™°ç„¡æ­§ç¾©
   - é©ç•¶çš„é›£åº¦åˆ†ä½ˆ

2. **é¸é …è¨­è¨ˆ**
   - ä¸€å€‹æ­£ç¢ºç­”æ¡ˆï¼Œä¸‰å€‹åˆç†çš„å¹²æ“¾é …
   - å¹²æ“¾é …è¦æœ‰è¿·æƒ‘æ€§ä½†æ˜ç¢ºéŒ¯èª¤
   - é¿å…"ä»¥ä¸Šçš†æ˜¯"æˆ–"ä»¥ä¸Šçš†é"çš„é¸é …
   - é¸é …é•·åº¦ç›¸è¿‘ï¼Œé¿å…æ˜é¡¯æç¤º

3. **è©•ä¼°æ•ˆæœ**
   - èƒ½æœ‰æ•ˆæ¸¬è©¦å­¸ç¿’æˆæœ
   - è¦†è“‹é‡è¦æ¦‚å¿µå’Œç´°ç¯€
   - æ”¯æŒè‡ªæˆ‘è©•ä¼°å’Œå¾©ç¿’
   - æä¾›å­¸ç¿’åé¥‹

**èªè¨€è¨­ç½®ï¼š**
{language_instruction}

**æ ¼å¼è¦æ±‚ï¼š**
è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å« 5 é“é¸æ“‡é¡Œï¼š

[
  {{
    "question": "å•é¡Œå…§å®¹",
    "options": ["Aé¸é …", "Bé¸é …", "Cé¸é …", "Dé¸é …"],
    "correct": "A",
    "explanation": "ç‚ºä»€éº¼é€™å€‹ç­”æ¡ˆæ­£ç¢ºçš„è©³ç´°è§£é‡‹"
  }}
]

åŸºæ–¼ä»¥ä¸‹ç­†è¨˜å…§å®¹å‰µå»ºæ¸¬é©—ï¼š
{notes}
"""
        
        try:
            response = openai.ChatCompletion.create(
                model=Config.OPENAI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2500,  # Increased for comprehensive quizzes
                temperature=0.5
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            raise Exception(f"Failed to generate quiz: {str(e)}")

    def generate_unified_notes(self, content, detail_level='medium', language='zh-tw', context_info=None):
        """Generate notes from multiple unified sources with enhanced context awareness"""
        
        if not context_info:
            context_info = {}
        
        # Enhanced language-specific instructions
        language_instructions = {
            'en': "Create comprehensive unified study notes in English from multiple sources. Integrate all content seamlessly while maintaining academic quality.",
            'zh-cn': "è¯·ä»å¤šä¸ªæ¥æºåˆ›å»ºå…¨é¢ç»Ÿä¸€çš„ç®€ä½“ä¸­æ–‡å­¦ä¹ ç¬”è®°ã€‚æ— ç¼æ•´åˆæ‰€æœ‰å†…å®¹ï¼Œä¿æŒå­¦æœ¯è´¨é‡ã€‚",
            'zh-tw': "è«‹å¾å¤šå€‹ä¾†æºå‰µå»ºå…¨é¢çµ±ä¸€çš„ç¹é«”ä¸­æ–‡å­¸ç¿’ç­†è¨˜ã€‚ç„¡ç¸«æ•´åˆæ‰€æœ‰å…§å®¹ï¼Œä¿æŒå­¸è¡“è³ªé‡ã€‚"
        }
        
        language_instruction = language_instructions.get(language, language_instructions['zh-tw'])
        
        # Context-aware prompt enhancement
        exam_context = ""
        if context_info.get('exam_system'):
            exam_system_names = {
                'ibdp': 'IB Diploma Programme',
                'al': 'A Level',
                'gcse': 'GCSE',
                'hkdse': 'HKDSE',
                'ap': 'Advanced Placement',
                'sat': 'SAT'
            }
            exam_name = exam_system_names.get(context_info['exam_system'], context_info['exam_system'])
            exam_context = f"é‡å° {exam_name} è€ƒè©¦ç³»çµ±"
        
        subject_context = ""
        if context_info.get('subject'):
            subject_names = {
                'chemistry': 'åŒ–å­¸',
                'physics': 'ç‰©ç†',
                'biology': 'ç”Ÿç‰©',
                'pure-mathematics': 'ç´”æ•¸å­¸',
                'computer-science': 'è¨ˆç®—æ©Ÿç§‘å­¸'
            }
            subject_name = subject_names.get(context_info['subject'], context_info['subject'])
            subject_context = f"ï¼Œç§‘ç›®ï¼š{subject_name}"
        
        topic_context = ""
        if context_info.get('topic') or context_info.get('custom_topic'):
            topic = context_info.get('custom_topic') or context_info.get('topic', '')
            topic_context = f"ï¼Œä¸»é¡Œï¼š{topic}"
        
        source_context = ""
        if context_info.get('sources'):
            source_types = [s['type'] for s in context_info['sources']]
            source_counts = {}
            for source_type in source_types:
                source_counts[source_type] = source_counts.get(source_type, 0) + 1
            
            source_descriptions = []
            for source_type, count in source_counts.items():
                type_names = {
                    'youtube': 'YouTube å½±ç‰‡',
                    'file': 'æ–‡ä»¶',
                    'text': 'æ–‡å­—å…§å®¹',
                    'webpage': 'ç¶²é '
                }
                type_name = type_names.get(source_type, source_type)
                source_descriptions.append(f"{count}å€‹{type_name}")
            
            source_context = f"ï¼Œæ•´åˆä¾†æºï¼š{', '.join(source_descriptions)}"

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¤šæºå­¸ç¿’å…§å®¹æ•´åˆå°ˆå®¶ã€‚{language_instruction}

## ä»»å‹™èƒŒæ™¯ï¼š
{exam_context}{subject_context}{topic_context}{source_context}

## å…§å®¹æ•´åˆè¦æ±‚ï¼š

### ğŸ¯ æ•´åˆåŸå‰‡ï¼š
1. **çµ±ä¸€æ€§** - å°‡æ‰€æœ‰ä¾†æºçš„å…§å®¹æ•´åˆç‚ºä¸€å€‹é€£è²«çš„å­¸ç¿’è³‡æº
2. **å±¤æ¬¡æ€§** - æŒ‰é‡è¦æ€§å’Œé‚è¼¯é †åºçµ„ç¹”å…§å®¹
3. **å®Œæ•´æ€§** - ä¿ç•™æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œé¿å…é‡è¤‡å’Œå†—é¤˜
4. **å­¸ç¿’å°å‘** - é‡å°{exam_context}çš„å­¸ç¿’å’Œè€ƒè©¦éœ€æ±‚å„ªåŒ–

### ğŸ“š ç­†è¨˜çµæ§‹ï¼š
1. **æ ¸å¿ƒæ¦‚å¿µç¸½è¦½** - æ‰€æœ‰ä¾†æºçš„é—œéµæ¦‚å¿µçµ±æ•´
2. **è©³ç´°å…§å®¹çµ„ç¹”** - æŒ‰é‚è¼¯ä¸»é¡Œåˆ†é¡æ•´åˆ
3. **é—œéµé»æå–** - é‡è¦å®šç¾©ã€å…¬å¼ã€ä¾‹å­
4. **å­¸ç¿’é‡é»** - è€ƒè©¦è¦é»å’Œé‡è¦çŸ¥è­˜é»
5. **å…§å®¹ä¾†æºæ¨™è¨»** - é©ç•¶æ¨™è¨»é‡è¦ä¿¡æ¯çš„ä¾†æºé¡å‹

### ğŸ” å…§å®¹è™•ç†ï¼š
- **å»é‡æ•´åˆ** - åˆä½µç›¸ä¼¼å…§å®¹ï¼Œè£œå……ä¸åŒè§’åº¦çš„ä¿¡æ¯
- **çµæ§‹å„ªåŒ–** - é‡æ–°çµ„ç¹”ç‚ºæœ€ä½³å­¸ç¿’é †åº
- **èªè¨€çµ±ä¸€** - ä½¿ç”¨ä¸€è‡´çš„è¡“èªå’Œè¡¨é”é¢¨æ ¼
- **æ·±åº¦æ•´åˆ** - å»ºç«‹ä¸åŒä¾†æºé–“çš„æ¦‚å¿µè¯ç¹«

### ğŸ“Š å“è³ªæ¨™æº–ï¼š
- **æº–ç¢ºæ€§** - ä¿æŒæ‰€æœ‰æŠ€è¡“ä¿¡æ¯çš„æº–ç¢ºæ€§
- **å®Œæ•´æ€§** - è¦†è“‹æ‰€æœ‰é‡è¦å­¸ç¿’å…§å®¹
- **å¯è®€æ€§** - æ¸…æ™°çš„çµæ§‹å’Œè¡¨é”
- **å¯¦ç”¨æ€§** - ä¾¿æ–¼è¤‡ç¿’å’Œè€ƒè©¦æº–å‚™

è«‹åŸºæ–¼ä»¥ä¸Šè¦æ±‚ï¼Œå°‡æä¾›çš„å¤šæºå…§å®¹æ•´åˆç‚ºé«˜è³ªé‡çš„çµ±ä¸€å­¸ç¿’ç­†è¨˜ï¼š

---

{content}

---

è«‹ç¢ºä¿ç”Ÿæˆçš„ç­†è¨˜å…·æœ‰æ¸…æ™°çš„çµæ§‹ã€è±å¯Œçš„å…§å®¹å’Œå„ªç§€çš„å­¸ç¿’åƒ¹å€¼ã€‚"""

        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": language_instruction},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating unified notes: {e}")
            return "æŠ±æ­‰ï¼Œç”Ÿæˆçµ±ä¸€ç­†è¨˜æ™‚å‡ºç¾éŒ¯èª¤ã€‚"